# Environment Variables Configuration
#
# This file contains example environment variables for the Model API.
# Copy this file to .env and customize the values for your environment.
#
# Usage:
#   cp .env.example .env
#   # Edit .env with your values
#   python src/app.py
#
# Author: AI Infrastructure Curriculum
# License: MIT

# =========================================================================
# Model Configuration
# =========================================================================

# Model name to load
# Options: resnet50, mobilenet_v2
# Default: resnet50
MODEL_NAME=resnet50

# Path to store/cache model weights
# Default: ~/.cache/torch/hub (standard PyTorch cache)
# You can specify a custom path if needed
MODEL_PATH=~/.cache/torch/hub

# Device to run inference on
# Options: cpu, cuda (if GPU available), mps (for Apple Silicon)
# Default: cpu
DEVICE=cpu

# =========================================================================
# API Configuration
# =========================================================================

# Host to bind the server to
# 0.0.0.0 = listen on all network interfaces (for Docker)
# 127.0.0.1 = listen on localhost only (for local development)
# Default: 0.0.0.0
HOST=0.0.0.0

# Port to listen on
# Default: 5000
# Note: Ports < 1024 require root privileges
PORT=5000

# Enable debug mode
# true = verbose logging, auto-reload on code changes
# false = production mode
# Default: false
# WARNING: Never enable debug in production!
DEBUG=false

# API version
# Follows semantic versioning (MAJOR.MINOR.PATCH)
# Default: 1.0.0
API_VERSION=1.0.0

# =========================================================================
# Request Limits
# =========================================================================

# Maximum file size for uploads (in bytes)
# Default: 10485760 (10MB)
# Prevents DOS attacks via huge file uploads
MAX_FILE_SIZE=10485760

# Maximum image dimension (width or height in pixels)
# Default: 4096
# Prevents memory issues from extremely large images
MAX_IMAGE_DIMENSION=4096

# Request timeout (in seconds)
# Default: 30
# Maximum time to process a single request
REQUEST_TIMEOUT=30

# Default number of predictions to return
# Default: 5
DEFAULT_TOP_K=5

# Maximum number of predictions allowed
# Default: 10
# Limits the maximum value of top_k parameter
MAX_TOP_K=10

# =========================================================================
# Logging Configuration
# =========================================================================

# Log level
# Options: DEBUG, INFO, WARNING, ERROR, CRITICAL
# Default: INFO
# - DEBUG: Very verbose, for development
# - INFO: Normal operational messages
# - WARNING: Warning messages (unusual but recoverable)
# - ERROR: Error messages (request failed)
# - CRITICAL: Critical issues (system failure)
LOG_LEVEL=INFO

# Log format
# Options: json, text
# Default: json
# - json: Structured logging (better for log aggregation)
# - text: Human-readable format (better for development)
LOG_FORMAT=json

# =========================================================================
# ImageNet Labels
# =========================================================================

# URL to download ImageNet class labels
# Default: PyTorch Hub GitHub repository
IMAGENET_LABELS_URL=https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt

# =========================================================================
# Performance Tuning (Advanced)
# =========================================================================

# Number of worker processes (for production deployment with Gunicorn)
# Default: 2
# Rule of thumb: (2 x num_cores) + 1
# WORKERS=2

# Number of threads per worker
# Default: 1
# Increase for I/O-bound workloads (not typically needed for ML inference)
# THREADS=1

# Worker timeout (seconds)
# Default: 30
# How long before killing unresponsive workers
# WORKER_TIMEOUT=30

# =========================================================================
# Cloud Configuration (for deployment)
# =========================================================================

# Cloud provider
# Options: aws, gcp, azure, local
# CLOUD_PROVIDER=aws

# Cloud region
# Example: us-east-1 (AWS), us-central1 (GCP), eastus (Azure)
# CLOUD_REGION=us-east-1

# =========================================================================
# Monitoring and Observability (Future)
# =========================================================================

# Enable Prometheus metrics endpoint
# ENABLE_METRICS=false

# Metrics port
# METRICS_PORT=9090

# Enable request tracing
# ENABLE_TRACING=false

# =========================================================================
# Security (Future)
# =========================================================================

# Enable API key authentication
# ENABLE_AUTH=false

# API key (if authentication enabled)
# WARNING: Never commit real API keys to git!
# API_KEY=your-secret-api-key-here

# Enable rate limiting
# ENABLE_RATE_LIMIT=false

# Rate limit: requests per minute
# RATE_LIMIT=100

# =========================================================================
# Database (Future Projects)
# =========================================================================

# Database URL (for storing predictions, metrics, etc.)
# Example: postgresql://user:password@localhost:5432/dbname
# DATABASE_URL=postgresql://localhost:5432/model_api

# =========================================================================
# Caching (Future Projects)
# =========================================================================

# Redis URL (for caching predictions)
# Example: redis://localhost:6379/0
# REDIS_URL=redis://localhost:6379/0

# Cache TTL (time to live) in seconds
# CACHE_TTL=3600

# =========================================================================
# Notes and Best Practices
# =========================================================================

# 1. Never commit .env files to version control
#    - Add .env to .gitignore
#    - Use .env.example for documentation
#    - Share .env files securely (encrypted, secret management)
#
# 2. Use different .env files for different environments
#    - .env.development
#    - .env.staging
#    - .env.production
#
# 3. Validate environment variables on startup
#    - Check required variables are set
#    - Validate types and ranges
#    - Fail fast if configuration is invalid
#
# 4. Use secrets management in production
#    - AWS Secrets Manager
#    - GCP Secret Manager
#    - Azure Key Vault
#    - HashiCorp Vault
#
# 5. Document all environment variables
#    - Include in this file
#    - Update when adding new variables
#    - Explain purpose and valid values

# =========================================================================
# Example Configurations
# =========================================================================

# Development (local machine):
# MODEL_NAME=resnet50
# DEVICE=cpu
# HOST=127.0.0.1
# PORT=5000
# DEBUG=true
# LOG_LEVEL=DEBUG
# LOG_FORMAT=text

# Production (cloud deployment):
# MODEL_NAME=resnet50
# DEVICE=cpu
# HOST=0.0.0.0
# PORT=5000
# DEBUG=false
# LOG_LEVEL=INFO
# LOG_FORMAT=json
# WORKERS=4

# Testing (CI/CD):
# MODEL_NAME=mobilenet_v2  # Smaller, faster for tests
# DEVICE=cpu
# LOG_LEVEL=ERROR
# MAX_FILE_SIZE=1048576  # 1MB limit for tests
